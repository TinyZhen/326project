{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TinyZhen/326project/blob/master/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **`Exploring different pretrained models in Hugging face`**"
      ],
      "metadata": {
        "id": "wLj0vB7F8hvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective: The primary goal of this assignment is to familiarize students with the Python programming environment and the use of pretrained models on Hugging Face. This foundational knowledge will be crucial for training and fine-tuning our own models in future assignments."
      ],
      "metadata": {
        "id": "9DsfUXw9UJSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Setup and Requirements Installation\n"
      ],
      "metadata": {
        "id": "iDUbBeK4WVnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "Jvy8keaETK7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Sentiment Analysis with a Pretrained Model:\n",
        "\n",
        "We will start with a sentiment analysis task using a pretrained model from Hugging Face. Access the model via this link:\n",
        "https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest\n",
        "\n",
        "\n",
        "Exercise 1:\n",
        "\n",
        "Use the following Python code to perform sentiment analysis. Your task is to modify the text variable with different prompts and observe how the model's sentiment predictions change. Pay attention to preprocessing the text for optimal model performance."
      ],
      "metadata": {
        "id": "uor5j93dWbkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up dependencies and load the model\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "# Preprocess text (username and link placeholders)\n",
        "def preprocess(text):\n",
        "    new_text = []\n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)\n",
        "\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "config = AutoConfig.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
      ],
      "metadata": {
        "id": "Co72jGtU8mcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example running case"
      ],
      "metadata": {
        "id": "lBPceWMPND2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Customize your input query\n",
        "text = \"I'm so happy!\"\n",
        "\n",
        "# Preprocess sentence before passing to the model\n",
        "text = preprocess(text)\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "# Pass the input to the model and get the raw output\n",
        "output = model(**encoded_input)\n",
        "scores = output[0][0].detach().numpy()\n",
        "scores = softmax(scores)\n",
        "\n",
        "# Print labels and scores\n",
        "ranking = np.argsort(scores)\n",
        "ranking = ranking[::-1]\n",
        "for i in range(scores.shape[0]):\n",
        "    l = config.id2label[ranking[i]]\n",
        "    s = scores[ranking[i]]\n",
        "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ],
      "metadata": {
        "id": "0QFfkoLTJWEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrate the sampling code into a single function"
      ],
      "metadata": {
        "id": "0o5Gw1-TNGvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clasifySentence(text):\n",
        "    # Preprocess sentence before passing to the model\n",
        "    text = preprocess(text)\n",
        "    encoded_input = tokenizer(text, return_tensors='pt')\n",
        "    # Pass the input to the model and get the raw output\n",
        "    output = model(**encoded_input)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "\n",
        "    # Print labels and scores\n",
        "    ranking = np.argsort(scores)\n",
        "    ranking = ranking[::-1]\n",
        "    for i in range(scores.shape[0]):\n",
        "        l = config.id2label[ranking[i]]\n",
        "        s = scores[ranking[i]]\n",
        "        print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ],
      "metadata": {
        "id": "LxNkOSt2M73a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clasifySentence('Today is a good day')"
      ],
      "metadata": {
        "id": "zU8k7rvCNlT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clasifySentence('I am learning AI today.')"
      ],
      "metadata": {
        "id": "IFIP1SWKNrW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clasifySentence('I feel headache.')"
      ],
      "metadata": {
        "id": "UnjnAhZ-N6c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2:\n",
        "\n",
        " * Select another sentiment analysis model from Hugging Face and compare its performance with the model used in Exercise 1.\n",
        "\n",
        " * Encapsulate the prediction task into a single function, like the example we provided in Exercise 1.\n",
        "\n",
        " * Compare the performance of the model with the one in Exercise 1. Document your findings.\n",
        "\n",
        "List of text classification pretrained models:\n",
        "\n",
        "https://huggingface.co/models?pipeline_tag=text-classification&sort=trending\n"
      ],
      "metadata": {
        "id": "bnSjUEDRW6Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO, write your code here"
      ],
      "metadata": {
        "id": "ig_3HxZDWBNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3:\n",
        "\n",
        " * Utilize the ResNet 50 pretrained model for image classification. You can access the model through this link:\n",
        " https://huggingface.co/microsoft/resnet-50\n",
        " * Your task is to encapsulate the prediction task into a single function, like the example we provided in Exercise 1.\n",
        " * Pick and upload your own images.\n",
        " * Classify and visualize 3 custom images using this model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ahAky9CdXUSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO, write your code here"
      ],
      "metadata": {
        "id": "fmXl8VA_SMZH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}